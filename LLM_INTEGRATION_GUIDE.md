# 🤖 LLM 기반 인사이트 생성 시스템

## 📋 개요

이탈자 분석 시스템에 **OpenAI GPT 모델**을 통합하여 실제 데이터를 기반으로 한 **지능형 인사이트와 권장 액션**을 자동 생성하는 기능이 추가되었습니다.

### ✨ 주요 기능
- 🧠 **AI 기반 분석**: GPT-4o-mini 모델을 활용한 데이터 분석
- 📊 **동적 인사이트**: 실제 데이터 패턴을 기반으로 한 맞춤형 인사이트
- 🎯 **실행 가능한 액션**: 구체적이고 실무에 바로 적용 가능한 권장사항
- 🔄 **자동 폴백**: LLM 실패 시 기존 로직으로 자동 전환
- 📈 **메타데이터 표시**: AI 분석 상태 및 정보 실시간 표시

---

## 🚀 설정 방법

### 1️⃣ **OpenAI API 키 설정**

#### **로컬 개발 환경**
```bash
# backend 디렉토리에 .env 파일 생성
cd backend
echo "OPENAI_API_KEY=your_openai_api_key_here" > .env
```

#### **Docker 환경**
```yaml
# docker-compose.yml에 환경 변수 추가
services:
  backend:
    environment:
      - OPENAI_API_KEY=your_openai_api_key_here
```

#### **API 키 발급 방법**
1. [OpenAI Platform](https://platform.openai.com/) 접속
2. 계정 생성 또는 로그인
3. API Keys 섹션에서 새 키 생성
4. 생성된 키를 안전하게 보관

### 2️⃣ **의존성 설치**

```bash
cd backend
pip install openai==1.68.0
```

### 3️⃣ **서버 재시작**

```bash
# 로컬 환경
uvicorn main:app --reload

# Docker 환경
docker-compose restart backend
```

---

## 🎯 사용 방법

### **기본 사용**
1. OpenAI API 키 설정 완료
2. 웹 인터페이스에서 "분석 실행" 클릭
3. AI 분석 결과가 리포트 탭에 자동 표시

### **AI 분석 상태 확인**
리포트 탭 하단의 "AI 분석 정보" 섹션에서 확인:
- ✅ **AI 분석 완료**: GPT 모델이 성공적으로 분석 완료
- ⚠️ **AI 분석 실패**: API 키 오류 등으로 기본 분석 사용
- ℹ️ **기본 분석 사용**: LLM 없이 기존 로직 사용

---

## 🧠 LLM 분석 프로세스

### **1단계: 데이터 요약**
```json
{
  "기본_지표": {
    "전체_이탈률": "23.5%",
    "활성_사용자": 89,
    "재활성_사용자": 12,
    "장기_미접속": 34
  },
  "세그먼트_분석": {
    "gender": [
      {"그룹": "F", "이탈률": "26.3%", "신뢰도": "확실"},
      {"그룹": "M", "이탈률": "20.1%", "신뢰도": "확실"}
    ]
  },
  "트렌드_분석": {
    "변화량": "+3.2%p",
    "트렌드": "상승"
  }
}
```

### **2단계: AI 프롬프트 생성**
- 시스템 프롬프트: 이탈 분석 전문가 역할 정의
- 사용자 프롬프트: 구체적인 데이터와 분석 요청
- 응답 형식: JSON 구조화된 결과

### **3단계: GPT 분석 실행**
```python
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[system_prompt, user_prompt],
    response_format={"type": "json_object"},
    temperature=0.7
)
```

### **4단계: 결과 검증 및 표시**
- JSON 파싱 및 유효성 검사
- 최대 3개 인사이트, 3개 액션 제한
- 메타데이터 추가 (모델명, 생성시간 등)

---

## 📊 LLM vs 기존 방식 비교

| 구분 | 기존 방식 | LLM 방식 |
|------|-----------|----------|
| **인사이트 생성** | 하드코딩된 조건문 | AI 기반 동적 분석 |
| **분석 깊이** | 단순 임계값 비교 | 복합적 패턴 인식 |
| **언어 품질** | 템플릿 기반 | 자연스러운 문장 |
| **맞춤화** | 제한적 | 데이터별 맞춤형 |
| **확장성** | 수동 코딩 필요 | 자동 적응 |

### **LLM 인사이트 예시**
```
기존: "여성 사용자의 이탈률이 높습니다."
LLM: "여성 사용자의 이탈률이 26.3%로 남성 대비 6.2%p 높으며, 
     특히 30대 여성에서 가장 두드러진 패턴을 보입니다."
```

---

## 🔧 고급 설정

### **모델 변경**
```python
# llm_service.py에서 모델 변경
response = self.client.chat.completions.create(
    model="gpt-4o-mini",  # 더 강력한 모델 사용
    # 또는 "gpt-3.5-turbo"  # 더 경제적인 모델
)
```

### **프롬프트 커스터마이징**
```python
def _get_system_prompt(self) -> str:
    return """당신은 [회사명] 이탈 분석 전문가입니다.
    [업계별 특화 지침 추가]
    [회사 특화 분석 기준 추가]
    """
```

### **비용 최적화**
- **모델 선택**: gpt-4o-mini (비용 효율적)
- **토큰 제한**: max_tokens=1500
- **캐싱**: Redis를 통한 결과 캐싱 (1시간)
- **조건부 실행**: 중요한 분석에만 LLM 사용

---

## 🚨 문제 해결

### **API 키 오류**
```
Error: OpenAI API key not found
```
**해결방법**: 
1. `.env` 파일에 `OPENAI_API_KEY` 설정 확인
2. 환경 변수 로드 확인: `python-dotenv` 설치
3. API 키 유효성 확인

### **모델 접근 오류**
```
Error: You don't have access to gpt-4o-mini
```
**해결방법**:
1. OpenAI 계정 결제 정보 확인
2. 모델을 `gpt-3.5-turbo`로 변경
3. API 사용량 한도 확인

### **JSON 파싱 오류**
```
Error: Invalid JSON response from LLM
```
**해결방법**:
1. 자동으로 기존 방식으로 폴백됨
2. 프롬프트 개선 필요 시 `_get_system_prompt()` 수정
3. temperature 값 조정 (0.5~0.8)

### **응답 속도 개선**
- **캐싱 활용**: 동일한 분석 결과 재사용
- **비동기 처리**: 백그라운드에서 LLM 실행
- **조건부 실행**: 데이터 변화가 클 때만 LLM 사용

---

## 💰 비용 관리

### **예상 비용** (GPT-4o-mini 기준)
- **분석 1회**: 약 $0.001~0.003
- **월 100회 분석**: 약 $0.10~0.30
- **연간 비용**: 약 $1.20~3.60

### **비용 절약 팁**
1. **캐싱 활용**: 동일 데이터 재분석 방지
2. **배치 처리**: 여러 분석을 한 번에 요청
3. **조건부 실행**: 유의미한 변화가 있을 때만 LLM 사용
4. **모델 선택**: 용도에 맞는 적절한 모델 선택

---

## 🔮 향후 확장 계획

### **단기 계획**
- [ ] 다국어 지원 (영어, 일본어)
- [ ] 커스텀 프롬프트 템플릿
- [ ] A/B 테스트 결과 분석

### **중기 계획**
- [ ] 이미지 차트 분석 (GPT-4V)
- [ ] 음성 리포트 생성 (TTS)
- [ ] 실시간 스트리밍 분석

### **장기 계획**
- [ ] 자체 Fine-tuned 모델
- [ ] 예측 모델링 통합
- [ ] 자동 액션 실행 시스템

---

## 📞 지원 및 문의

- **기술 문의**: GitHub Issues
- **API 관련**: OpenAI 공식 문서 참조
- **커스터마이징**: 개발팀 문의

**LLM 통합으로 더욱 지능적인 이탈 분석을 경험해보세요!** 🚀
