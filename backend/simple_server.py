"""
ê°„ë‹¨í•œ LLM ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì„œë²„ (ë°ì´í„°ë² ì´ìŠ¤ ì—†ì´)
"""
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict
import os
from dotenv import load_dotenv
import json
from datetime import datetime
from analytics import ChurnAnalyzer
from database import get_db

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

app = FastAPI(title="Simple Churn Analysis API", version="1.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class AnalysisRequest(BaseModel):
    start_month: str = "2025-08"
    end_month: str = "2025-10"
    segments: dict = {"gender": True, "age_band": True, "channel": True}
    calculated_metrics: dict = None  # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ê³„ì‚°ëœ ë©”íŠ¸ë¦­

def _filter_responses(responses: List[str]) -> List[str]:
    """ì‘ë‹µ í•„í„°ë§ ë° ê²€ì¦"""
    if not responses:
        return []
    
    filtered_responses = []
    prohibited_terms = [
        'ê°œì¸ì •ë³´', 'ë¯¼ê°ì •ë³´', 'ë²•ì ', 'ì˜ë£Œ', 'ì°¨ë³„', 'í¸í–¥', 
        'ì¶”ì¸¡', 'ê°€ì •', 'í™•ì‹¤í•˜ì§€', 'ë¶ˆí™•ì‹¤', 'ê³¼ì¥'
    ]
    
    for response in responses:
        if not isinstance(response, str) or len(response.strip()) == 0:
            continue
            
        # ê¸ˆì§€ëœ ìš©ì–´ê°€ í¬í•¨ëœ ì‘ë‹µ í•„í„°ë§
        if any(term in response for term in prohibited_terms):
            print(f"[WARNING] ê¸ˆì§€ëœ ìš©ì–´ê°€ í¬í•¨ëœ ì‘ë‹µ í•„í„°ë§: {response[:50]}...")
            continue
        
        # ì‘ë‹µ ê¸¸ì´ ê²€ì¦ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ì‘ë‹µ ì œì™¸)
        if len(response) < 10 or len(response) > 500:
            print(f"[WARNING] ë¶€ì ì ˆí•œ ê¸¸ì´ì˜ ì‘ë‹µ í•„í„°ë§: {len(response)}ì")
            continue
        
        # ê¸°ë³¸ì ì¸ í’ˆì§ˆ ê²€ì¦ í†µê³¼
        filtered_responses.append(response.strip())
    
    # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
    return filtered_responses[:3]

def get_real_metrics(request: AnalysisRequest) -> Dict:
    """ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    try:
        print(f"[DEBUG] get_real_metrics í˜¸ì¶œë¨: {request.start_month} ~ {request.end_month}")
        print(f"[DEBUG] ì„¸ê·¸ë¨¼íŠ¸ ì„¤ì •: {request.segments}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        db = next(get_db())
        print("[DEBUG] ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
        
        # ChurnAnalyzer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        analyzer = ChurnAnalyzer(db)
        print("[DEBUG] ChurnAnalyzer ìƒì„± ì™„ë£Œ")
        
        # ì‹¤ì œ ë¶„ì„ ì‹¤í–‰
        result = analyzer.run_full_analysis(
            start_month=request.start_month,
            end_month=request.end_month,
            segments=request.segments
        )
        print(f"[DEBUG] ë¶„ì„ ê²°ê³¼: {result}")
        
        # ë©”íŠ¸ë¦­ë§Œ ì¶”ì¶œ
        if "error" in result:
            print(f"[ERROR] ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {result['error']}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "churn_rate": 0.0,
                "active_users": 0,
                "reactivated_users": 0,
                "long_term_inactive": 0
            }
        
        metrics = result.get("metrics", {})
        print(f"[DEBUG] ì¶”ì¶œëœ ë©”íŠ¸ë¦­: {metrics}")
        
        final_metrics = {
            "churn_rate": metrics.get("churn_rate", 0.0),
            "active_users": metrics.get("active_users", 0),
            "reactivated_users": metrics.get("reactivated_users", 0),
            "long_term_inactive": metrics.get("long_term_inactive", 0)
        }
        print(f"[DEBUG] ìµœì¢… ë©”íŠ¸ë¦­: {final_metrics}")
        
        return final_metrics
        
    except Exception as e:
        print(f"[ERROR] ë©”íŠ¸ë¦­ ê³„ì‚° ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return {
            "churn_rate": 0.0,
            "active_users": 0,
            "reactivated_users": 0,
            "long_term_inactive": 0
        }

@app.get("/")
async def root():
    return {"message": "Simple Churn Analysis API", "version": "1.0.0"}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": datetime.now()}

@app.post("/analysis/run")
async def run_analysis(request: AnalysisRequest):
    """LLM ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    
    # OpenAI API í‚¤ í™•ì¸
    api_key = os.getenv('OPENAI_API_KEY')
    
    if not api_key or api_key == 'your_openai_api_key_here':
        return {
            "analysis_id": f"demo_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "timestamp": datetime.now().isoformat(),
            "insights": [
                "ğŸ”‘ OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ë©´ ì‹¤ì œ AI ë¶„ì„ì„ ê²½í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "ğŸ“Š í˜„ì¬ëŠ” ë°ëª¨ ëª¨ë“œë¡œ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.",
                "âš™ï¸ .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ê³  ì„œë²„ë¥¼ ì¬ì‹œì‘í•˜ì„¸ìš”."
            ],
            "actions": [
                "ğŸŒ https://platform.openai.com ì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ìœ¼ì„¸ìš”.",
                "ğŸ“ backend/.env íŒŒì¼ì„ ìˆ˜ì •í•˜ì—¬ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
                "ğŸ”„ ì„œë²„ë¥¼ ì¬ì‹œì‘í•˜ë©´ AI ë¶„ì„ì´ í™œì„±í™”ë©ë‹ˆë‹¤."
            ],
            "llm_metadata": {
                "model_used": None,
                "generation_method": "api_key_required",
                "fallback_used": True,
                "setup_required": True,
                "timestamp": datetime.now().isoformat()
            },
            "metrics": get_real_metrics(request)
        }
    
    # API í‚¤ê°€ ìˆìœ¼ë©´ ì‹¤ì œ LLM í˜¸ì¶œ
    try:
        from openai import OpenAI
        
        client = OpenAI(api_key=api_key)
        
        # ì‹¤ì œ ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        segment_data = []
        
        try:
            db = next(get_db())
            analyzer = ChurnAnalyzer(db)
            
            # ì‹¤ì œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ ìˆ˜í–‰
            if request.segments.get("gender", False):
                gender_results = analyzer._analyze_segment("gender", request.start_month, request.end_month)
                if gender_results:
                    gender_text = []
                    for result in gender_results:
                        gender_name = "ë‚¨ì„±" if result['segment_value'] == 'M' else "ì—¬ì„±"
                        gender_text.append(f"{gender_name}: {result['churn_rate']}%")
                    segment_data.append(f"- ì„±ë³„ ì´íƒˆë¥ : {', '.join(gender_text)}")
            
            if request.segments.get("age_band", False):
                age_results = analyzer._analyze_segment("age_band", request.start_month, request.end_month)
                if age_results:
                    age_text = []
                    for result in age_results:
                        age_name = f"{result['segment_value']}ëŒ€"
                        age_text.append(f"{age_name}: {result['churn_rate']}%")
                    segment_data.append(f"- ì—°ë ¹ëŒ€ ì´íƒˆë¥ : {', '.join(age_text)}")
            
            if request.segments.get("channel", False):
                channel_results = analyzer._analyze_segment("channel", request.start_month, request.end_month)
                if channel_results:
                    channel_text = []
                    for result in channel_results:
                        channel_name = "ì›¹" if result['segment_value'] == 'web' else "ì•±"
                        channel_text.append(f"{channel_name}: {result['churn_rate']}%")
                    segment_data.append(f"- ì±„ë„ ì´íƒˆë¥ : {', '.join(channel_text)}")
                    
        except Exception as e:
            print(f"[ERROR] ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ë©”ì‹œì§€
            if any(request.segments.values()):
                segment_data.append("- ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        
        segment_section = "\n".join(segment_data) if segment_data else "- ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        # ì‹¤ì œ ë©”íŠ¸ë¦­ ê°€ì ¸ì˜¤ê¸° (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬ëœ ê²ƒ ìš°ì„  ì‚¬ìš©)
        if request.calculated_metrics:
            real_metrics = request.calculated_metrics
            print(f"[DEBUG] í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬ëœ ë©”íŠ¸ë¦­ ì‚¬ìš©: {real_metrics}")
        else:
            real_metrics = get_real_metrics(request)
            print(f"[DEBUG] ë°±ì—”ë“œì—ì„œ ê³„ì‚°ëœ ë©”íŠ¸ë¦­ ì‚¬ìš©: {real_metrics}")
        
        # ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""ë‹¤ìŒ ì´íƒˆ ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ 3ê°œì™€ ê¶Œì¥ ì•¡ì…˜ 3ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

## ë¶„ì„ ë°ì´í„°
- ë¶„ì„ ê¸°ê°„: {request.start_month} ~ {request.end_month}
- ì „ì²´ ì´íƒˆë¥ : {real_metrics['churn_rate']:.1f}%
- í™œì„± ì‚¬ìš©ì: {real_metrics['active_users']:,}ëª…
- ì¬í™œì„± ì‚¬ìš©ì: {real_metrics['reactivated_users']:,}ëª…
- ì¥ê¸° ë¯¸ì ‘ì†: {real_metrics['long_term_inactive']:,}ëª…

## ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„
{segment_section}

ì£¼ì˜ì‚¬í•­:
- ì„ íƒë˜ì§€ ì•Šì€ ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•´ì„œëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
- ì‹¤ì œ ë°ì´í„° ìˆ˜ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œì¥ì‚¬í•­ì„ ì œì‹œí•˜ì„¸ìš”

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”: {{"insights": [...], "actions": [...]}}
"""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": """ë‹¹ì‹ ì€ ì‚¬ìš©ì ì´íƒˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì¸ì‚¬ì´íŠ¸ì™€ ê¶Œì¥ ì•¡ì…˜ì„ ì œê³µí•˜ì„¸ìš”.

ì ˆëŒ€ í•˜ì§€ ë§ì•„ì•¼ í•  ê²ƒë“¤:
- ì¶”ì¸¡ì´ë‚˜ ê°€ì •ì— ê¸°ë°˜í•œ ë¶„ì„ ê¸ˆì§€
- ë°ì´í„°ì— ì—†ëŠ” ì •ë³´ë¥¼ ì„ì˜ë¡œ ì¶”ê°€í•˜ì§€ ë§ ê²ƒ
- ê°œì¸ì •ë³´ë‚˜ ë¯¼ê°í•œ ì •ë³´ ì–¸ê¸‰ ê¸ˆì§€
- ë¹„ìœ¤ë¦¬ì ì´ê±°ë‚˜ ì°¨ë³„ì ì¸ ê¶Œì¥ì‚¬í•­ ì œì‹œ ê¸ˆì§€
- ë²•ì  ì¡°ì–¸ì´ë‚˜ ì˜ë£Œì  ì¡°ì–¸ ì œê³µ ê¸ˆì§€
- ë§ˆì¼€íŒ…ì´ë‚˜ ì˜ì—… ëª©ì ì˜ ê³¼ì¥ëœ í‘œí˜„ ì‚¬ìš© ê¸ˆì§€
- ì„ íƒë˜ì§€ ì•Šì€ ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ ì–¸ê¸‰ ê¸ˆì§€
- í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•Šì€ ì°¨ì´ë¥¼ ê³¼ì¥í•˜ì—¬ ì„¤ëª… ê¸ˆì§€
- ë¶ˆí™•ì‹¤í•œ ë°ì´í„°ë¥¼ í™•ì‹¤í•œ ê²ƒì²˜ëŸ¼ í‘œí˜„ ê¸ˆì§€"""
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            response_format={"type": "json_object"},
            temperature=0.7,
            max_tokens=1000
        )
        
        result = json.loads(response.choices[0].message.content)
        
        # ì‘ë‹µ í•„í„°ë§ ë° ê²€ì¦
        insights = _filter_responses(result.get('insights', [])[:3])
        actions = _filter_responses(result.get('actions', [])[:3])
        
        return {
            "analysis_id": f"llm_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "timestamp": datetime.now().isoformat(),
            "insights": insights,
            "actions": actions,
            "llm_metadata": {
                "model_used": "gpt-4o-mini",
                "generation_method": "llm",
                "fallback_used": False,
                "setup_required": False,
                "timestamp": datetime.now().isoformat()
            },
            "metrics": get_real_metrics(request)
        }
        
    except Exception as e:
        return {
            "analysis_id": f"error_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "timestamp": datetime.now().isoformat(),
            "insights": [
                f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.",
                "ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            ],
            "actions": [
                "OpenAI API í‚¤ê°€ ìœ íš¨í•œì§€ í™•ì¸í•˜ì„¸ìš”.",
                "ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.",
                "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”."
            ],
            "llm_metadata": {
                "model_used": None,
                "generation_method": "error",
                "fallback_used": True,
                "setup_required": True,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            },
            "metrics": {
                "churn_rate": 0,
                "active_users": 0,
                "reactivated_users": 0,
                "long_term_inactive": 0
            }
        }

if __name__ == "__main__":
    import uvicorn
    print("Simple Churn Analysis Server ì‹œì‘...")
    print("http://localhost:8000 ì—ì„œ API ì„œë²„ ì‹¤í–‰")
    print("AI ë¶„ì„ì„ ìœ„í•´ OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”")
    uvicorn.run(app, host="0.0.0.0", port=8000)
