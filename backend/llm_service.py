"""
LLM ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ë° ê¶Œì¥ ì•¡ì…˜ ìƒì„± ì„œë¹„ìŠ¤
"""
import os
import json
from typing import Dict, List, Optional
from datetime import datetime
import openai
from openai import OpenAI
import logging

logger = logging.getLogger(__name__)

class LLMInsightGenerator:
    """LLMì„ í™œìš©í•œ ì´íƒˆ ë¶„ì„ ì¸ì‚¬ì´íŠ¸ ìƒì„±ê¸°"""
    
    def __init__(self):
        self.client = None
        self._initialize_client()
    
    def _initialize_client(self):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            logger.warning("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LLM ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
            return
        
        try:
            self.client = OpenAI(api_key=api_key)
            logger.info("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def generate_insights_and_actions(self, analysis_data: Dict) -> Dict[str, List[str]]:
        """
        ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì„ í†µí•´ ì¸ì‚¬ì´íŠ¸ì™€ ê¶Œì¥ ì•¡ì…˜ ìƒì„±
        
        Args:
            analysis_data: ì´íƒˆ ë¶„ì„ ê²°ê³¼ ë°ì´í„°
            
        Returns:
            Dict containing 'insights' and 'actions' lists
        """
        if not self.client:
            logger.warning("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return self._generate_fallback_insights(analysis_data)
        
        try:
            # ë°ì´í„° ìš”ì•½ ìƒì„±
            data_summary = self._create_data_summary(analysis_data)
            
            # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_analysis_prompt(data_summary)
            
            # OpenAI API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",  # ë¹„ìš© íš¨ìœ¨ì ì¸ ëª¨ë¸ ì‚¬ìš©
                messages=[
                    {
                        "role": "system",
                        "content": self._get_system_prompt()
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                response_format={"type": "json_object"},
                temperature=0.7,
                max_tokens=1500
            )
            
            # ì‘ë‹µ íŒŒì‹±
            result = json.loads(response.choices[0].message.content)
            
            # ê²°ê³¼ ê²€ì¦ ë° ì •ì œ
            insights = result.get('insights', [])[:3]  # ìµœëŒ€ 3ê°œ
            actions = result.get('actions', [])[:3]    # ìµœëŒ€ 3ê°œ
            
            # ì‘ë‹µ í•„í„°ë§ ë° ê²€ì¦
            insights = self._filter_and_validate_responses(insights, 'insights')
            actions = self._filter_and_validate_responses(actions, 'actions')
            
            logger.info(f"LLM ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ: {len(insights)}ê°œ ì¸ì‚¬ì´íŠ¸, {len(actions)}ê°œ ì•¡ì…˜")
            
            return {
                'insights': insights,
                'actions': actions,
                'generated_by': 'llm',
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"LLM ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return self._generate_fallback_insights(analysis_data)
    
    def _get_system_prompt(self) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜"""
        return """ë‹¹ì‹ ì€ ì‚¬ìš©ì ì´íƒˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì¸ì‚¬ì´íŠ¸ì™€ ê¶Œì¥ ì•¡ì…˜ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

ì‘ë‹µ ê·œì¹™:
1. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”: {"insights": [...], "actions": [...]}
2. ì¸ì‚¬ì´íŠ¸ëŠ” ë°ì´í„°ì—ì„œ ë°œê²¬ëœ ì¤‘ìš”í•œ íŒ¨í„´ì´ë‚˜ íŠ¸ë Œë“œë¥¼ ì„¤ëª…
3. ê¶Œì¥ ì•¡ì…˜ì€ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆì„ ì œì‹œ
4. ê°ê° ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ì œê³µ
5. í•œêµ­ì–´ë¡œ ì‘ì„±
6. ë°ì´í„°ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ë¶ˆí™•ì‹¤í•œ ê²½ìš° "Uncertain" í‘œê¸°
7. í†µê³„ì ìœ¼ë¡œ ì˜ë¯¸ ìˆëŠ” ì°¨ì´(5%p ì´ìƒ)ë§Œ ì–¸ê¸‰

ë¶„ì„ ê´€ì :
- ì„¸ê·¸ë¨¼íŠ¸ë³„ ì´íƒˆë¥  ì°¨ì´
- ì‹œê°„ë³„ íŠ¸ë Œë“œ ë³€í™”
- ì¬í™œì„±í™” íŒ¨í„´
- ìœ„í—˜ ì‚¬ìš©ì ê·¸ë£¹
- ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ

ì ˆëŒ€ í•˜ì§€ ë§ì•„ì•¼ í•  ê²ƒë“¤:
- ì¶”ì¸¡ì´ë‚˜ ê°€ì •ì— ê¸°ë°˜í•œ ë¶„ì„ ê¸ˆì§€
- ë°ì´í„°ì— ì—†ëŠ” ì •ë³´ë¥¼ ì„ì˜ë¡œ ì¶”ê°€í•˜ì§€ ë§ ê²ƒ
- ê°œì¸ì •ë³´ë‚˜ ë¯¼ê°í•œ ì •ë³´ ì–¸ê¸‰ ê¸ˆì§€
- ë¹„ìœ¤ë¦¬ì ì´ê±°ë‚˜ ì°¨ë³„ì ì¸ ê¶Œì¥ì‚¬í•­ ì œì‹œ ê¸ˆì§€
- ë²•ì  ì¡°ì–¸ì´ë‚˜ ì˜ë£Œì  ì¡°ì–¸ ì œê³µ ê¸ˆì§€
- ë§ˆì¼€íŒ…ì´ë‚˜ ì˜ì—… ëª©ì ì˜ ê³¼ì¥ëœ í‘œí˜„ ì‚¬ìš© ê¸ˆì§€
- ì„ íƒë˜ì§€ ì•Šì€ ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ ì–¸ê¸‰ ê¸ˆì§€
- í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•Šì€ ì°¨ì´ë¥¼ ê³¼ì¥í•˜ì—¬ ì„¤ëª… ê¸ˆì§€
- ë¶ˆí™•ì‹¤í•œ ë°ì´í„°ë¥¼ í™•ì‹¤í•œ ê²ƒì²˜ëŸ¼ í‘œí˜„ ê¸ˆì§€"""

    def _create_data_summary(self, analysis_data: Dict) -> Dict:
        """ë¶„ì„ ë°ì´í„°ë¥¼ LLMì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ìš”ì•½"""
        
        summary = {
            "ê¸°ë³¸_ì§€í‘œ": {},
            "ì„¸ê·¸ë¨¼íŠ¸_ë¶„ì„": {},
            "íŠ¸ë Œë“œ_ë¶„ì„": {},
            "ë°ì´í„°_í’ˆì§ˆ": {},
            "ì„ íƒëœ_ì„¸ê·¸ë¨¼íŠ¸": {}
        }
        
        # ê¸°ë³¸ ì§€í‘œ ìš”ì•½
        metrics = analysis_data.get('metrics', {})
        summary["ê¸°ë³¸_ì§€í‘œ"] = {
            "ì „ì²´_ì´íƒˆë¥ ": f"{metrics.get('churn_rate', 0):.1f}%",
            "í™œì„±_ì‚¬ìš©ì": metrics.get('active_users', 0),
            "ì¬í™œì„±_ì‚¬ìš©ì": metrics.get('reactivated_users', 0),
            "ì¥ê¸°_ë¯¸ì ‘ì†": metrics.get('long_term_inactive', 0),
            "ë¶„ì„_ê¸°ê°„": f"{analysis_data.get('start_month', 'N/A')} ~ {analysis_data.get('end_month', 'N/A')}"
        }
        
        # ì„ íƒëœ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ì¶”ê°€
        config = analysis_data.get('config', {})
        selected_segments = config.get('segments', {})
        summary["ì„ íƒëœ_ì„¸ê·¸ë¨¼íŠ¸"] = {
            "ì„±ë³„_ë¶„ì„": selected_segments.get('gender', False),
            "ì—°ë ¹ëŒ€_ë¶„ì„": selected_segments.get('age_band', False),
            "ì±„ë„_ë¶„ì„": selected_segments.get('channel', False)
        }
        
        # ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ ìš”ì•½ (ì„ íƒëœ ì„¸ê·¸ë¨¼íŠ¸ë§Œ)
        segments = analysis_data.get('segments', {})
        segment_names = {
            'gender': 'ì„±ë³„',
            'age_band': 'ì—°ë ¹ëŒ€', 
            'channel': 'ì±„ë„'
        }
        
        for segment_type, segment_data in segments.items():
            if segment_data and selected_segments.get(segment_type, False):
                segment_summary = []
                for item in segment_data:
                    segment_summary.append({
                        "ê·¸ë£¹": item.get('segment_value', 'Unknown'),
                        "ì´íƒˆë¥ ": f"{item.get('churn_rate', 0):.1f}%",
                        "í™œì„±ì‚¬ìš©ì": item.get('current_active', 0),
                        "ì‹ ë¢°ë„": "Uncertain" if item.get('is_uncertain', False) else "í™•ì‹¤"
                    })
                summary["ì„¸ê·¸ë¨¼íŠ¸_ë¶„ì„"][segment_names.get(segment_type, segment_type)] = segment_summary
        
        # íŠ¸ë Œë“œ ë¶„ì„ ìš”ì•½
        trends = analysis_data.get('trends', {})
        if trends:
            trend_data = trends.get('monthly_churn_rates', [])
            if len(trend_data) >= 2:
                first_rate = trend_data[0].get('churn_rate', 0)
                last_rate = trend_data[-1].get('churn_rate', 0)
                change = last_rate - first_rate
                
                summary["íŠ¸ë Œë“œ_ë¶„ì„"] = {
                    "ê¸°ê°„": f"{len(trend_data)}ê°œì›”",
                    "ì‹œì‘_ì´íƒˆë¥ ": f"{first_rate:.1f}%",
                    "ìµœì¢…_ì´íƒˆë¥ ": f"{last_rate:.1f}%",
                    "ë³€í™”ëŸ‰": f"{change:+.1f}%p",
                    "íŠ¸ë Œë“œ": "ìƒìŠ¹" if change > 1 else "í•˜ë½" if change < -1 else "ì•ˆì •"
                }
        
        # ë°ì´í„° í’ˆì§ˆ ìš”ì•½
        quality = analysis_data.get('data_quality', {})
        summary["ë°ì´í„°_í’ˆì§ˆ"] = {
            "ì´_ì´ë²¤íŠ¸": quality.get('total_events', 0),
            "ìœ íš¨_ì´ë²¤íŠ¸": quality.get('valid_events', 0),
            "ì™„ì „ì„±": f"{quality.get('data_completeness', 0):.1f}%",
            "ì•Œìˆ˜ì—†ìŒ_ë¹„ìœ¨": f"{quality.get('unknown_ratio', 0):.1f}%"
        }
        
        return summary
    
    def _create_analysis_prompt(self, data_summary: Dict) -> str:
        """LLM ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        # ì„ íƒëœ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ í™•ì¸
        selected_segments = data_summary.get('ì„ íƒëœ_ì„¸ê·¸ë¨¼íŠ¸', {})
        segment_analysis_available = any(selected_segments.values())
        
        prompt = f"""ë‹¤ìŒ ì´íƒˆ ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ 3ê°œì™€ ê¶Œì¥ ì•¡ì…˜ 3ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

## ë¶„ì„ ì„¤ì •

### ì„ íƒëœ ì„¸ê·¸ë¨¼íŠ¸
{json.dumps(data_summary['ì„ íƒëœ_ì„¸ê·¸ë¨¼íŠ¸'], ensure_ascii=False, indent=2)}

## ë¶„ì„ ë°ì´í„°

### ê¸°ë³¸ ì§€í‘œ
{json.dumps(data_summary['ê¸°ë³¸_ì§€í‘œ'], ensure_ascii=False, indent=2)}"""

        # ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ì´ ìˆëŠ” ê²½ìš°ë§Œ í¬í•¨
        if segment_analysis_available and data_summary['ì„¸ê·¸ë¨¼íŠ¸_ë¶„ì„']:
            prompt += f"""

### ì„¸ê·¸ë¨¼íŠ¸ë³„ ë¶„ì„ (ì„ íƒëœ ì„¸ê·¸ë¨¼íŠ¸ë§Œ)
{json.dumps(data_summary['ì„¸ê·¸ë¨¼íŠ¸_ë¶„ì„'], ensure_ascii=False, indent=2)}"""
        else:
            prompt += """

### ì„¸ê·¸ë¨¼íŠ¸ë³„ ë¶„ì„
ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì „ì²´ ì‚¬ìš©ì ê¸°ì¤€ìœ¼ë¡œë§Œ ë¶„ì„í•˜ì„¸ìš”."""

        prompt += f"""

### íŠ¸ë Œë“œ ë¶„ì„
{json.dumps(data_summary['íŠ¸ë Œë“œ_ë¶„ì„'], ensure_ascii=False, indent=2)}

### ë°ì´í„° í’ˆì§ˆ
{json.dumps(data_summary['ë°ì´í„°_í’ˆì§ˆ'], ensure_ascii=False, indent=2)}

## ìš”ì²­ì‚¬í•­

1. **ì£¼ìš” ì¸ì‚¬ì´íŠ¸ 3ê°œ**: ë°ì´í„°ì—ì„œ ë°œê²¬ëœ ê°€ì¥ ì¤‘ìš”í•œ íŒ¨í„´ì´ë‚˜ ë¬¸ì œì 
2. **ê¶Œì¥ ì•¡ì…˜ 3ê°œ**: ì´íƒˆë¥  ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë°©ì•ˆ

ì£¼ì˜ì‚¬í•­:
- ì„ íƒë˜ì§€ ì•Šì€ ì„¸ê·¸ë¨¼íŠ¸(ì„±ë³„/ì—°ë ¹ëŒ€/ì±„ë„)ì— ëŒ€í•´ì„œëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
- ì„ íƒëœ ì„¸ê·¸ë¨¼íŠ¸ë§Œ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”
- í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´(5%p ì´ìƒ)ë§Œ ì–¸ê¸‰
- ë°ì´í„°ê°€ ë¶€ì¡±í•œ ì„¸ê·¸ë¨¼íŠ¸ëŠ” "Uncertain" í‘œê¸°
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ í•¨ê»˜ ì„¤ëª…
- ì‹¤ë¬´ì§„ì´ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì•¡ì…˜ ì œì‹œ

ê¸ˆì§€ì‚¬í•­:
- ë°ì´í„°ì— ì—†ëŠ” ì •ë³´ë¥¼ ì¶”ì¸¡í•˜ê±°ë‚˜ ê°€ì •í•˜ì§€ ë§ˆì„¸ìš”
- ê°œì¸ì •ë³´ë‚˜ ë¯¼ê°í•œ ì •ë³´ë¥¼ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
- ì°¨ë³„ì ì´ê±°ë‚˜ í¸í–¥ëœ ë¶„ì„ì„ ì œê³µí•˜ì§€ ë§ˆì„¸ìš”
- ë²•ì  ì¡°ì–¸ì´ë‚˜ ì˜ë£Œì  ì¡°ì–¸ì„ ì œê³µí•˜ì§€ ë§ˆì„¸ìš”
- ê³¼ì¥ë˜ê±°ë‚˜ ë¶€ì •í™•í•œ í‘œí˜„ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ì„ íƒë˜ì§€ ì•Šì€ ì„¸ê·¸ë¨¼íŠ¸ì˜ ë°ì´í„°ë¥¼ ì„ì˜ë¡œ í•´ì„í•˜ì§€ ë§ˆì„¸ìš”
- í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•Šì€ ì°¨ì´ë¥¼ ê³¼ì¥í•˜ì—¬ ì„¤ëª…í•˜ì§€ ë§ˆì„¸ìš”
- ë¶ˆí™•ì‹¤í•œ ë°ì´í„°ë¥¼ í™•ì‹¤í•œ ê²ƒì²˜ëŸ¼ í‘œí˜„í•˜ì§€ ë§ˆì„¸ìš”"""

        return prompt
    
    def _filter_and_validate_responses(self, responses: List[str], response_type: str) -> List[str]:
        """ì‘ë‹µ í•„í„°ë§ ë° ê²€ì¦"""
        if not responses:
            return []
        
        filtered_responses = []
        prohibited_terms = [
            'ê°œì¸ì •ë³´', 'ë¯¼ê°ì •ë³´', 'ë²•ì ', 'ì˜ë£Œ', 'ì°¨ë³„', 'í¸í–¥', 
            'ì¶”ì¸¡', 'ê°€ì •', 'í™•ì‹¤í•˜ì§€', 'ë¶ˆí™•ì‹¤', 'ê³¼ì¥'
        ]
        
        for response in responses:
            if not isinstance(response, str) or len(response.strip()) == 0:
                continue
                
            # ê¸ˆì§€ëœ ìš©ì–´ê°€ í¬í•¨ëœ ì‘ë‹µ í•„í„°ë§
            if any(term in response for term in prohibited_terms):
                logger.warning(f"ê¸ˆì§€ëœ ìš©ì–´ê°€ í¬í•¨ëœ {response_type} ì‘ë‹µ í•„í„°ë§: {response[:50]}...")
                continue
            
            # ì‘ë‹µ ê¸¸ì´ ê²€ì¦ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ì‘ë‹µ ì œì™¸)
            if len(response) < 10 or len(response) > 500:
                logger.warning(f"ë¶€ì ì ˆí•œ ê¸¸ì´ì˜ {response_type} ì‘ë‹µ í•„í„°ë§: {len(response)}ì")
                continue
            
            # ê¸°ë³¸ì ì¸ í’ˆì§ˆ ê²€ì¦ í†µê³¼
            filtered_responses.append(response.strip())
        
        # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
        return filtered_responses[:3]
    
    def _generate_fallback_insights(self, analysis_data: Dict) -> Dict[str, List[str]]:
        """LLM ì‚¬ìš© ë¶ˆê°€ ì‹œ API í‚¤ ì„¤ì • ì•ˆë‚´"""
        
        return {
            'insights': [
                "ğŸ¤– AI ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ìœ„í•´ OpenAI API í‚¤ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "ğŸ“Š API í‚¤ ì„¤ì • í›„ ì‹¤ì œ ë°ì´í„° íŒ¨í„´ì„ ë¶„ì„í•œ ë§ì¶¤í˜• ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "âš™ï¸ LLM_INTEGRATION_GUIDE.md ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì—¬ ì„¤ì •ì„ ì™„ë£Œí•˜ì„¸ìš”."
            ],
            'actions': [
                "ğŸ”‘ OpenAI Platformì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ìœ¼ì„¸ìš”.",
                "ğŸ“ backend/.env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.",
                "ğŸ”„ ì„œë²„ë¥¼ ì¬ì‹œì‘í•˜ë©´ AI ê¸°ë°˜ ë¶„ì„ì´ í™œì„±í™”ë©ë‹ˆë‹¤."
            ],
            'generated_by': 'api_key_required',
            'timestamp': datetime.now().isoformat(),
            'setup_required': True
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
llm_generator = LLMInsightGenerator()
